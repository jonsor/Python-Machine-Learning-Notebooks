{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision trees can be used both for classification and regression.\n",
    "Essentially decision trees learn a hierarchy of if/else questions, similar to the game 20 Questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "\n",
    "mglearn.plots.plot_animal_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulding a Decision Tree\n",
    "To build a decision tree the algorthm searches over all the tests (questions) in order to find the feature which splits the most data. In this example \"Has feathers?\" is the most informative question.\n",
    "\n",
    "### Avoiding overfitting\n",
    "If a decision tree is built until all leaves are pure leads to models, the remaining tree will be very complex and very likely to overfit to the training data.\n",
    "\n",
    "There are two common strategies to prevent overfitting: \n",
    "1. `pre-pruning:` stopping the creating of the tree early.\n",
    "2. `post-pruning:` removing or collapsing nodes that contain little information after the tree is built.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at an example with the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load dataset\n",
    "cancer = datasets.load_breast_cancer()\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "# Create and fit Decision Tree\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example no pruning was used. As you can see the accuracy on the training set is 100% which means that all the leaves are pure.\n",
    "\n",
    "Let's use some `pre-pruning` and limit the depth (number of consequtive questions) of the Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"720pt\" height=\"350pt\"\r\n",
       " viewBox=\"0.00 0.00 720.00 350.34\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.444033 0.444033) rotate(0) translate(4 785)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-785 1617.5,-785 1617.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.403922\" stroke=\"black\" d=\"M1119.5,-781C1119.5,-781 982.5,-781 982.5,-781 976.5,-781 970.5,-775 970.5,-769 970.5,-769 970.5,-725 970.5,-725 970.5,-719 976.5,-713 982.5,-713 982.5,-713 1119.5,-713 1119.5,-713 1125.5,-713 1131.5,-719 1131.5,-725 1131.5,-725 1131.5,-769 1131.5,-769 1131.5,-775 1125.5,-781 1119.5,-781\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1051\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst radius &lt;= 16.795</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1051\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 426</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1051\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [159, 267]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1051\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.901961\" stroke=\"black\" d=\"M1019,-677C1019,-677 833,-677 833,-677 827,-677 821,-671 821,-665 821,-665 821,-621 821,-621 821,-615 827,-609 833,-609 833,-609 1019,-609 1019,-609 1025,-609 1031,-615 1031,-621 1031,-621 1031,-665 1031,-665 1031,-671 1025,-677 1019,-677\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst concave points &lt;= 0.136</text>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 284</text>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 259]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1010.42,-712.884C999.064,-703.62 986.606,-693.455 974.83,-683.845\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"976.769,-680.91 966.808,-677.299 972.343,-686.333 976.769,-680.91\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"969.328\" y=\"-698.472\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 28 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>28</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.941176\" stroke=\"black\" d=\"M1242,-677C1242,-677 1112,-677 1112,-677 1106,-677 1100,-671 1100,-665 1100,-665 1100,-621 1100,-621 1100,-615 1106,-609 1112,-609 1112,-609 1242,-609 1242,-609 1248,-609 1254,-615 1254,-621 1254,-621 1254,-665 1254,-665 1254,-671 1248,-677 1242,-677\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">texture error &lt;= 0.473</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 142</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [134, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;28 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>0&#45;&gt;28</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1091.91,-712.884C1103.35,-703.62 1115.91,-693.455 1127.78,-683.845\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1130.3,-686.312 1135.87,-677.299 1125.89,-680.871 1130.3,-686.312\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1133.25\" y=\"-698.462\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.984314\" stroke=\"black\" d=\"M728.5,-573C728.5,-573 603.5,-573 603.5,-573 597.5,-573 591.5,-567 591.5,-561 591.5,-561 591.5,-517 591.5,-517 591.5,-511 597.5,-505 603.5,-505 603.5,-505 728.5,-505 728.5,-505 734.5,-505 740.5,-511 740.5,-517 740.5,-517 740.5,-561 740.5,-561 740.5,-567 734.5,-573 728.5,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">radius error &lt;= 1.048</text>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 252</text>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 248]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M841.585,-608.884C812.284,-597.388 779.444,-584.505 750.163,-573.018\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"751.377,-569.735 740.79,-569.341 748.821,-576.251 751.377,-569.735\"/>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.474510\" stroke=\"black\" d=\"M993,-573C993,-573 859,-573 859,-573 853,-573 847,-567 847,-561 847,-561 847,-517 847,-517 847,-511 853,-505 859,-505 859,-505 993,-505 993,-505 999,-505 1005,-511 1005,-517 1005,-517 1005,-561 1005,-561 1005,-567 999,-573 993,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst texture &lt;= 25.62</text>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"926\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;17 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>1&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M926,-608.884C926,-600.778 926,-591.982 926,-583.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"929.5,-583.299 926,-573.299 922.5,-583.299 929.5,-583.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.988235\" stroke=\"black\" d=\"M502.5,-469C502.5,-469 337.5,-469 337.5,-469 331.5,-469 325.5,-463 325.5,-457 325.5,-457 325.5,-413 325.5,-413 325.5,-407 331.5,-401 337.5,-401 337.5,-401 502.5,-401 502.5,-401 508.5,-401 514.5,-407 514.5,-413 514.5,-413 514.5,-457 514.5,-457 514.5,-463 508.5,-469 502.5,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">smoothness error &lt;= 0.003</text>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 251</text>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 248]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M591.19,-506.981C565.395,-496.286 536.24,-484.197 509.398,-473.068\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.588,-469.772 500.01,-469.175 507.907,-476.238 510.588,-469.772\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M716.5,-461.5C716.5,-461.5 615.5,-461.5 615.5,-461.5 609.5,-461.5 603.5,-455.5 603.5,-449.5 603.5,-449.5 603.5,-420.5 603.5,-420.5 603.5,-414.5 609.5,-408.5 615.5,-408.5 615.5,-408.5 716.5,-408.5 716.5,-408.5 722.5,-408.5 728.5,-414.5 728.5,-420.5 728.5,-420.5 728.5,-449.5 728.5,-449.5 728.5,-455.5 722.5,-461.5 716.5,-461.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"666\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>2&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M666,-504.884C666,-494.326 666,-482.597 666,-471.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"669.5,-471.52 666,-461.52 662.5,-471.52 669.5,-471.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" d=\"M252.5,-365C252.5,-365 125.5,-365 125.5,-365 119.5,-365 113.5,-359 113.5,-353 113.5,-353 113.5,-309 113.5,-309 113.5,-303 119.5,-297 125.5,-297 125.5,-297 252.5,-297 252.5,-297 258.5,-297 264.5,-303 264.5,-309 264.5,-309 264.5,-353 264.5,-353 264.5,-359 258.5,-365 252.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean texture &lt;= 19.9</text>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M345.001,-400.884C322.09,-390.767 296.744,-379.575 273.261,-369.206\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.579,-365.962 264.018,-365.125 271.752,-372.366 274.579,-365.962\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.992157\" stroke=\"black\" d=\"M473.5,-365C473.5,-365 366.5,-365 366.5,-365 360.5,-365 354.5,-359 354.5,-353 354.5,-353 354.5,-309 354.5,-309 354.5,-303 360.5,-297 366.5,-297 366.5,-297 473.5,-297 473.5,-297 479.5,-297 485.5,-303 485.5,-309 485.5,-309 485.5,-353 485.5,-353 485.5,-359 479.5,-365 473.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">area error &lt;= 48.7</text>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 247</text>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 245]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"420\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420,-400.884C420,-392.778 420,-383.982 420,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"423.5,-375.299 420,-365.299 416.5,-375.299 423.5,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M96,-253.5C96,-253.5 12,-253.5 12,-253.5 6,-253.5 0,-247.5 0,-241.5 0,-241.5 0,-212.5 0,-212.5 0,-206.5 6,-200.5 12,-200.5 12,-200.5 96,-200.5 96,-200.5 102,-200.5 108,-206.5 108,-212.5 108,-212.5 108,-241.5 108,-241.5 108,-247.5 102,-253.5 96,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.169,-296.884C129.303,-284.896 111.44,-271.399 95.7566,-259.549\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"97.865,-256.756 87.7764,-253.52 93.6451,-262.341 97.865,-256.756\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M239.5,-253.5C239.5,-253.5 138.5,-253.5 138.5,-253.5 132.5,-253.5 126.5,-247.5 126.5,-241.5 126.5,-241.5 126.5,-212.5 126.5,-212.5 126.5,-206.5 132.5,-200.5 138.5,-200.5 138.5,-200.5 239.5,-200.5 239.5,-200.5 245.5,-200.5 251.5,-206.5 251.5,-212.5 251.5,-212.5 251.5,-241.5 251.5,-241.5 251.5,-247.5 245.5,-253.5 239.5,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189,-296.884C189,-286.326 189,-274.597 189,-263.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-263.52 189,-253.52 185.5,-263.52 192.5,-263.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.996078\" stroke=\"black\" d=\"M416,-261C416,-261 282,-261 282,-261 276,-261 270,-255 270,-249 270,-249 270,-205 270,-205 270,-199 276,-193 282,-193 282,-193 416,-193 416,-193 422,-193 428,-199 428,-205 428,-205 428,-249 428,-249 428,-255 422,-261 416,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"349\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst texture &lt;= 33.35</text>\r\n",
       "<text text-anchor=\"middle\" x=\"349\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 243</text>\r\n",
       "<text text-anchor=\"middle\" x=\"349\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 242]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"349\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M396.948,-296.884C390.872,-288.154 384.239,-278.625 377.897,-269.514\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.765,-267.507 372.179,-261.299 375.019,-271.506 380.765,-267.507\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" d=\"M609.5,-261C609.5,-261 458.5,-261 458.5,-261 452.5,-261 446.5,-255 446.5,-249 446.5,-249 446.5,-205 446.5,-205 446.5,-199 452.5,-193 458.5,-193 458.5,-193 609.5,-193 609.5,-193 615.5,-193 621.5,-199 621.5,-205 621.5,-205 621.5,-249 621.5,-249 621.5,-255 615.5,-261 609.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean concavity &lt;= 0.029</text>\r\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\r\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>7&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.013,-296.884C467.266,-287.709 478.509,-277.65 489.157,-268.123\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"491.664,-270.576 496.783,-261.299 486.997,-265.359 491.664,-270.576\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M251.5,-149.5C251.5,-149.5 162.5,-149.5 162.5,-149.5 156.5,-149.5 150.5,-143.5 150.5,-137.5 150.5,-137.5 150.5,-108.5 150.5,-108.5 150.5,-102.5 156.5,-96.5 162.5,-96.5 162.5,-96.5 251.5,-96.5 251.5,-96.5 257.5,-96.5 263.5,-102.5 263.5,-108.5 263.5,-108.5 263.5,-137.5 263.5,-137.5 263.5,-143.5 257.5,-149.5 251.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 225</text>\r\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 225]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M302.897,-192.884C286.208,-180.896 267.418,-167.399 250.922,-155.549\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.692,-152.511 242.528,-149.52 248.608,-158.197 252.692,-152.511\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.941176\" stroke=\"black\" d=\"M418.5,-157C418.5,-157 293.5,-157 293.5,-157 287.5,-157 281.5,-151 281.5,-145 281.5,-145 281.5,-101 281.5,-101 281.5,-95 287.5,-89 293.5,-89 293.5,-89 418.5,-89 418.5,-89 424.5,-89 430.5,-95 430.5,-101 430.5,-101 430.5,-145 430.5,-145 430.5,-151 424.5,-157 418.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst texture &lt;= 33.8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\r\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 17]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.273,-192.884C351.829,-184.778 352.433,-175.982 353.017,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"356.522,-167.516 353.715,-157.299 349.538,-167.036 356.522,-167.516\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M338.5,-53C338.5,-53 237.5,-53 237.5,-53 231.5,-53 225.5,-47 225.5,-41 225.5,-41 225.5,-12 225.5,-12 225.5,-6 231.5,-0 237.5,-0 237.5,-0 338.5,-0 338.5,-0 344.5,-0 350.5,-6 350.5,-12 350.5,-12 350.5,-41 350.5,-41 350.5,-47 344.5,-53 338.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"288\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"288\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"288\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M332.217,-88.9485C325.832,-80.0749 318.916,-70.4648 312.493,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"315.201,-59.3094 306.52,-53.2367 309.519,-63.398 315.201,-59.3094\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M465,-53C465,-53 381,-53 381,-53 375,-53 369,-47 369,-41 369,-41 369,-12 369,-12 369,-6 375,-0 381,-0 381,-0 465,-0 465,-0 471,-0 477,-6 477,-12 477,-12 477,-41 477,-41 477,-47 471,-53 465,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"423\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\r\n",
       "<text text-anchor=\"middle\" x=\"423\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 17]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"423\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>10&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M379.433,-88.9485C385.725,-80.0749 392.538,-70.4648 398.867,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"401.824,-63.4188 404.753,-53.2367 396.114,-59.3701 401.824,-63.4188\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M576.5,-149.5C576.5,-149.5 475.5,-149.5 475.5,-149.5 469.5,-149.5 463.5,-143.5 463.5,-137.5 463.5,-137.5 463.5,-108.5 463.5,-108.5 463.5,-102.5 469.5,-96.5 475.5,-96.5 475.5,-96.5 576.5,-96.5 576.5,-96.5 582.5,-96.5 588.5,-102.5 588.5,-108.5 588.5,-108.5 588.5,-137.5 588.5,-137.5 588.5,-143.5 582.5,-149.5 576.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"526\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"526\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"526\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M531.403,-192.884C530.566,-182.216 529.635,-170.352 528.786,-159.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"532.273,-159.216 528.002,-149.52 525.294,-159.763 532.273,-159.216\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M703,-149.5C703,-149.5 619,-149.5 619,-149.5 613,-149.5 607,-143.5 607,-137.5 607,-137.5 607,-108.5 607,-108.5 607,-102.5 613,-96.5 619,-96.5 619,-96.5 703,-96.5 703,-96.5 709,-96.5 715,-102.5 715,-108.5 715,-108.5 715,-137.5 715,-137.5 715,-143.5 709,-149.5 703,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"661\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"661\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"661\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>13&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.233,-192.884C590.022,-181.006 606.656,-167.646 621.311,-155.876\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"623.62,-158.511 629.225,-149.52 619.237,-153.053 623.62,-158.511\"/>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" d=\"M931.5,-469C931.5,-469 812.5,-469 812.5,-469 806.5,-469 800.5,-463 800.5,-457 800.5,-457 800.5,-413 800.5,-413 800.5,-407 806.5,-401 812.5,-401 812.5,-401 931.5,-401 931.5,-401 937.5,-401 943.5,-407 943.5,-413 943.5,-413 943.5,-457 943.5,-457 943.5,-463 937.5,-469 931.5,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst area &lt;= 817.1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 17&#45;&gt;18 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M908.468,-504.884C903.988,-496.422 899.11,-487.207 894.421,-478.352\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"897.401,-476.5 889.629,-469.299 891.215,-479.775 897.401,-476.5\"/>\r\n",
       "</g>\r\n",
       "<!-- 23 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>23</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.890196\" stroke=\"black\" d=\"M1138,-469C1138,-469 986,-469 986,-469 980,-469 974,-463 974,-457 974,-457 974,-413 974,-413 974,-407 980,-401 986,-401 986,-401 1138,-401 1138,-401 1144,-401 1150,-407 1150,-413 1150,-413 1150,-457 1150,-457 1150,-463 1144,-469 1138,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst symmetry &lt;= 0.268</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 17&#45;&gt;23 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>17&#45;&gt;23</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M970.155,-504.884C982.626,-495.531 996.321,-485.259 1009.24,-475.568\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1011.7,-478.099 1017.6,-469.299 1007.5,-472.499 1011.7,-478.099\"/>\r\n",
       "</g>\r\n",
       "<!-- 19 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.890196\" stroke=\"black\" d=\"M779,-365C779,-365 609,-365 609,-365 603,-365 597,-359 597,-353 597,-353 597,-309 597,-309 597,-303 603,-297 609,-297 609,-297 779,-297 779,-297 785,-297 791,-303 791,-309 791,-309 791,-353 791,-353 791,-359 785,-365 779,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean smoothness &lt;= 0.123</text>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 18&#45;&gt;19 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>18&#45;&gt;19</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M814.209,-400.884C797.179,-391.125 778.404,-380.366 760.855,-370.31\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"762.223,-367.06 751.806,-365.125 758.742,-373.133 762.223,-367.06\"/>\r\n",
       "</g>\r\n",
       "<!-- 22 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>22</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M922.5,-357.5C922.5,-357.5 821.5,-357.5 821.5,-357.5 815.5,-357.5 809.5,-351.5 809.5,-345.5 809.5,-345.5 809.5,-316.5 809.5,-316.5 809.5,-310.5 815.5,-304.5 821.5,-304.5 821.5,-304.5 922.5,-304.5 922.5,-304.5 928.5,-304.5 934.5,-310.5 934.5,-316.5 934.5,-316.5 934.5,-345.5 934.5,-345.5 934.5,-351.5 928.5,-357.5 922.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"872\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 18&#45;&gt;22 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>18&#45;&gt;22</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M872,-400.884C872,-390.326 872,-378.597 872,-367.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"875.5,-367.52 872,-357.52 868.5,-367.52 875.5,-367.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 20 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>20</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M736,-253.5C736,-253.5 652,-253.5 652,-253.5 646,-253.5 640,-247.5 640,-241.5 640,-241.5 640,-212.5 640,-212.5 640,-206.5 646,-200.5 652,-200.5 652,-200.5 736,-200.5 736,-200.5 742,-200.5 748,-206.5 748,-212.5 748,-212.5 748,-241.5 748,-241.5 748,-247.5 742,-253.5 736,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 19&#45;&gt;20 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>19&#45;&gt;20</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M694,-296.884C694,-286.326 694,-274.597 694,-263.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"697.5,-263.52 694,-253.52 690.5,-263.52 697.5,-263.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 21 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>21</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M879.5,-253.5C879.5,-253.5 778.5,-253.5 778.5,-253.5 772.5,-253.5 766.5,-247.5 766.5,-241.5 766.5,-241.5 766.5,-212.5 766.5,-212.5 766.5,-206.5 772.5,-200.5 778.5,-200.5 778.5,-200.5 879.5,-200.5 879.5,-200.5 885.5,-200.5 891.5,-206.5 891.5,-212.5 891.5,-212.5 891.5,-241.5 891.5,-241.5 891.5,-247.5 885.5,-253.5 879.5,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"829\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"829\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"829\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 19&#45;&gt;21 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>19&#45;&gt;21</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737.831,-296.884C753.697,-284.896 771.56,-271.399 787.243,-259.549\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"789.355,-262.341 795.224,-253.52 785.135,-256.756 789.355,-262.341\"/>\r\n",
       "</g>\r\n",
       "<!-- 24 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>24</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M1159,-365C1159,-365 965,-365 965,-365 959,-365 953,-359 953,-353 953,-353 953,-309 953,-309 953,-303 959,-297 965,-297 965,-297 1159,-297 1159,-297 1165,-297 1171,-303 1171,-309 1171,-309 1171,-353 1171,-353 1171,-359 1165,-365 1159,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">fractal dimension error &lt;= 0.002</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 23&#45;&gt;24 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>23&#45;&gt;24</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1062,-400.884C1062,-392.778 1062,-383.982 1062,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1065.5,-375.299 1062,-365.299 1058.5,-375.299 1065.5,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 27 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>27</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1302.5,-357.5C1302.5,-357.5 1201.5,-357.5 1201.5,-357.5 1195.5,-357.5 1189.5,-351.5 1189.5,-345.5 1189.5,-345.5 1189.5,-316.5 1189.5,-316.5 1189.5,-310.5 1195.5,-304.5 1201.5,-304.5 1201.5,-304.5 1302.5,-304.5 1302.5,-304.5 1308.5,-304.5 1314.5,-310.5 1314.5,-316.5 1314.5,-316.5 1314.5,-345.5 1314.5,-345.5 1314.5,-351.5 1308.5,-357.5 1302.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1252\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1252\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1252\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 23&#45;&gt;27 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>23&#45;&gt;27</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1123.69,-400.884C1146.84,-388.456 1173.01,-374.406 1195.65,-362.252\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1197.31,-365.334 1204.46,-357.52 1194,-359.166 1197.31,-365.334\"/>\r\n",
       "</g>\r\n",
       "<!-- 25 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>25</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1067.5,-253.5C1067.5,-253.5 966.5,-253.5 966.5,-253.5 960.5,-253.5 954.5,-247.5 954.5,-241.5 954.5,-241.5 954.5,-212.5 954.5,-212.5 954.5,-206.5 960.5,-200.5 966.5,-200.5 966.5,-200.5 1067.5,-200.5 1067.5,-200.5 1073.5,-200.5 1079.5,-206.5 1079.5,-212.5 1079.5,-212.5 1079.5,-241.5 1079.5,-241.5 1079.5,-247.5 1073.5,-253.5 1067.5,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1017\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1017\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1017\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 24&#45;&gt;25 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>24&#45;&gt;25</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1047.39,-296.884C1042.59,-285.996 1037.23,-273.863 1032.37,-262.85\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1035.5,-261.256 1028.26,-253.52 1029.09,-264.082 1035.5,-261.256\"/>\r\n",
       "</g>\r\n",
       "<!-- 26 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>26</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1194,-253.5C1194,-253.5 1110,-253.5 1110,-253.5 1104,-253.5 1098,-247.5 1098,-241.5 1098,-241.5 1098,-212.5 1098,-212.5 1098,-206.5 1104,-200.5 1110,-200.5 1110,-200.5 1194,-200.5 1194,-200.5 1200,-200.5 1206,-206.5 1206,-212.5 1206,-212.5 1206,-241.5 1206,-241.5 1206,-247.5 1200,-253.5 1194,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1152\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1152\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1152\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 24&#45;&gt;26 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>24&#45;&gt;26</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1091.22,-296.884C1101.31,-285.446 1112.62,-272.634 1122.71,-261.19\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1125.49,-263.334 1129.48,-253.52 1120.24,-258.703 1125.49,-263.334\"/>\r\n",
       "</g>\r\n",
       "<!-- 29 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>29</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1219,-565.5C1219,-565.5 1135,-565.5 1135,-565.5 1129,-565.5 1123,-559.5 1123,-553.5 1123,-553.5 1123,-524.5 1123,-524.5 1123,-518.5 1129,-512.5 1135,-512.5 1135,-512.5 1219,-512.5 1219,-512.5 1225,-512.5 1231,-518.5 1231,-524.5 1231,-524.5 1231,-553.5 1231,-553.5 1231,-559.5 1225,-565.5 1219,-565.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1177\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 28&#45;&gt;29 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>28&#45;&gt;29</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1177,-608.884C1177,-598.326 1177,-586.597 1177,-575.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1180.5,-575.52 1177,-565.52 1173.5,-575.52 1180.5,-575.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 30 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>30</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.976471\" stroke=\"black\" d=\"M1461.5,-573C1461.5,-573 1312.5,-573 1312.5,-573 1306.5,-573 1300.5,-567 1300.5,-561 1300.5,-561 1300.5,-517 1300.5,-517 1300.5,-511 1306.5,-505 1312.5,-505 1312.5,-505 1461.5,-505 1461.5,-505 1467.5,-505 1473.5,-511 1473.5,-517 1473.5,-517 1473.5,-561 1473.5,-561 1473.5,-567 1467.5,-573 1461.5,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst concavity &lt;= 0.191</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 137</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [134, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 28&#45;&gt;30 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>28&#45;&gt;30</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1245.18,-608.884C1265.73,-598.901 1288.44,-587.872 1309.55,-577.619\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1311.34,-580.642 1318.8,-573.125 1308.28,-574.346 1311.34,-580.642\"/>\r\n",
       "</g>\r\n",
       "<!-- 31 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>31</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.333333\" stroke=\"black\" d=\"M1458,-469C1458,-469 1316,-469 1316,-469 1310,-469 1304,-463 1304,-457 1304,-457 1304,-413 1304,-413 1304,-407 1310,-401 1316,-401 1316,-401 1458,-401 1458,-401 1464,-401 1470,-407 1470,-413 1470,-413 1470,-457 1470,-457 1470,-463 1464,-469 1458,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst texture &lt;= 30.975</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 30&#45;&gt;31 -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>30&#45;&gt;31</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1387,-504.884C1387,-496.778 1387,-487.982 1387,-479.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1390.5,-479.299 1387,-469.299 1383.5,-479.299 1390.5,-479.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 34 -->\r\n",
       "<g id=\"node35\" class=\"node\"><title>34</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1601.5,-461.5C1601.5,-461.5 1500.5,-461.5 1500.5,-461.5 1494.5,-461.5 1488.5,-455.5 1488.5,-449.5 1488.5,-449.5 1488.5,-420.5 1488.5,-420.5 1488.5,-414.5 1494.5,-408.5 1500.5,-408.5 1500.5,-408.5 1601.5,-408.5 1601.5,-408.5 1607.5,-408.5 1613.5,-414.5 1613.5,-420.5 1613.5,-420.5 1613.5,-449.5 1613.5,-449.5 1613.5,-455.5 1607.5,-461.5 1601.5,-461.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1551\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 132</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1551\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [132, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1551\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 30&#45;&gt;34 -->\r\n",
       "<g id=\"edge34\" class=\"edge\"><title>30&#45;&gt;34</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1440.25,-504.884C1459.87,-492.676 1482.02,-478.903 1501.32,-466.899\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1503.32,-469.773 1509.97,-461.52 1499.63,-463.829 1503.32,-469.773\"/>\r\n",
       "</g>\r\n",
       "<!-- 32 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>32</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1429,-357.5C1429,-357.5 1345,-357.5 1345,-357.5 1339,-357.5 1333,-351.5 1333,-345.5 1333,-345.5 1333,-316.5 1333,-316.5 1333,-310.5 1339,-304.5 1345,-304.5 1345,-304.5 1429,-304.5 1429,-304.5 1435,-304.5 1441,-310.5 1441,-316.5 1441,-316.5 1441,-345.5 1441,-345.5 1441,-351.5 1435,-357.5 1429,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 31&#45;&gt;32 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>31&#45;&gt;32</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1387,-400.884C1387,-390.326 1387,-378.597 1387,-367.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1390.5,-367.52 1387,-357.52 1383.5,-367.52 1390.5,-367.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 33 -->\r\n",
       "<g id=\"node34\" class=\"node\"><title>33</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1572.5,-357.5C1572.5,-357.5 1471.5,-357.5 1471.5,-357.5 1465.5,-357.5 1459.5,-351.5 1459.5,-345.5 1459.5,-345.5 1459.5,-316.5 1459.5,-316.5 1459.5,-310.5 1465.5,-304.5 1471.5,-304.5 1471.5,-304.5 1572.5,-304.5 1572.5,-304.5 1578.5,-304.5 1584.5,-310.5 1584.5,-316.5 1584.5,-316.5 1584.5,-345.5 1584.5,-345.5 1584.5,-351.5 1578.5,-357.5 1572.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1522\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1522\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1522\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 31&#45;&gt;33 -->\r\n",
       "<g id=\"edge33\" class=\"edge\"><title>31&#45;&gt;33</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1430.83,-400.884C1446.7,-388.896 1464.56,-375.399 1480.24,-363.549\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1482.35,-366.341 1488.22,-357.52 1478.13,-360.756 1482.35,-366.341\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x227395ae5c0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "# Create image of tree with graphviz\n",
    "dot_data = export_graphviz(tree, out_file=None, class_names=[\"malignant\", \"benign\"],feature_names=cancer.feature_names, impurity=False, filled=True, rounded=True)\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "pydot_graph.set_size('\"10,10!\"')\n",
    "\n",
    "gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
    "gvz_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.977\n",
      "Accuracy on test set: 0.944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# Create and fit Decision Tree with pruning\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=2)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the accuracy on the training set is lower and the accuracy on the test set is higher, which means we have reduced overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"720pt\" height=\"309pt\"\r\n",
       " viewBox=\"0.00 0.00 720.00 308.69\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.827586 0.827586) rotate(0) translate(4 369)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-369 866,-369 866,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.403922\" stroke=\"black\" d=\"M525,-365C525,-365 388,-365 388,-365 382,-365 376,-359 376,-353 376,-353 376,-309 376,-309 376,-303 382,-297 388,-297 388,-297 525,-297 525,-297 531,-297 537,-303 537,-309 537,-309 537,-353 537,-353 537,-359 531,-365 525,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"456.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst radius &lt;= 16.795</text>\r\n",
       "<text text-anchor=\"middle\" x=\"456.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 426</text>\r\n",
       "<text text-anchor=\"middle\" x=\"456.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [159, 267]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"456.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.901961\" stroke=\"black\" d=\"M449.5,-261C449.5,-261 263.5,-261 263.5,-261 257.5,-261 251.5,-255 251.5,-249 251.5,-249 251.5,-205 251.5,-205 251.5,-199 257.5,-193 263.5,-193 263.5,-193 449.5,-193 449.5,-193 455.5,-193 461.5,-199 461.5,-205 461.5,-205 461.5,-249 461.5,-249 461.5,-255 455.5,-261 449.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"356.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst concave points &lt;= 0.136</text>\r\n",
       "<text text-anchor=\"middle\" x=\"356.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 284</text>\r\n",
       "<text text-anchor=\"middle\" x=\"356.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 259]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"356.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M424.033,-296.884C415.213,-287.887 405.559,-278.041 396.381,-268.678\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"398.646,-265.99 389.146,-261.299 393.648,-270.89 398.646,-265.99\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"388.899\" y=\"-282.598\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.941176\" stroke=\"black\" d=\"M621.5,-261C621.5,-261 491.5,-261 491.5,-261 485.5,-261 479.5,-255 479.5,-249 479.5,-249 479.5,-205 479.5,-205 479.5,-199 485.5,-193 491.5,-193 491.5,-193 621.5,-193 621.5,-193 627.5,-193 633.5,-199 633.5,-205 633.5,-205 633.5,-249 633.5,-249 633.5,-255 627.5,-261 621.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">texture error &lt;= 0.473</text>\r\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 142</text>\r\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [134, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>0&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M488.967,-296.884C497.787,-287.887 507.441,-278.041 516.619,-268.678\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"519.352,-270.89 523.854,-261.299 514.354,-265.99 519.352,-270.89\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"524.101\" y=\"-282.598\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.984314\" stroke=\"black\" d=\"M260,-157C260,-157 111,-157 111,-157 105,-157 99,-151 99,-145 99,-145 99,-101 99,-101 99,-95 105,-89 111,-89 111,-89 260,-89 260,-89 266,-89 272,-95 272,-101 272,-101 272,-145 272,-145 272,-151 266,-157 260,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">symmetry error &lt;= 0.009</text>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 252</text>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 248]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.981,-192.884C284.621,-183.125 266.584,-172.366 249.726,-162.31\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"251.414,-159.242 241.033,-157.125 247.828,-165.253 251.414,-159.242\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.474510\" stroke=\"black\" d=\"M436.5,-157C436.5,-157 302.5,-157 302.5,-157 296.5,-157 290.5,-151 290.5,-145 290.5,-145 290.5,-101 290.5,-101 290.5,-95 296.5,-89 302.5,-89 302.5,-89 436.5,-89 436.5,-89 442.5,-89 448.5,-95 448.5,-101 448.5,-101 448.5,-145 448.5,-145 448.5,-151 442.5,-157 436.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"369.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst texture &lt;= 25.62</text>\r\n",
       "<text text-anchor=\"middle\" x=\"369.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"middle\" x=\"369.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"369.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M360.721,-192.884C361.754,-184.778 362.875,-175.982 363.959,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.464,-167.662 365.256,-157.299 360.52,-166.777 367.464,-167.662\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M113,-53C113,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 113,-0 113,-0 119,-0 125,-6 125,-12 125,-12 125,-41 125,-41 125,-47 119,-53 113,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.481,-88.9485C129.978,-79.3431 116.353,-68.8747 103.949,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.061,-56.5537 95.9986,-53.2367 101.796,-62.1046 106.061,-56.5537\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.988235\" stroke=\"black\" d=\"M244,-53C244,-53 155,-53 155,-53 149,-53 143,-47 143,-41 143,-41 143,-12 143,-12 143,-6 149,-0 155,-0 155,-0 244,-0 244,-0 250,-0 256,-6 256,-12 256,-12 256,-41 256,-41 256,-47 250,-53 244,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"199.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 251</text>\r\n",
       "<text text-anchor=\"middle\" x=\"199.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 248]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"199.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.397,-88.9485C191.63,-80.6238 192.959,-71.6509 194.211,-63.2027\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.684,-63.6417 195.687,-53.2367 190.759,-62.6158 197.684,-63.6417\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" d=\"M397.5,-53C397.5,-53 313.5,-53 313.5,-53 307.5,-53 301.5,-47 301.5,-41 301.5,-41 301.5,-12 301.5,-12 301.5,-6 307.5,-0 313.5,-0 313.5,-0 397.5,-0 397.5,-0 403.5,-0 409.5,-6 409.5,-12 409.5,-12 409.5,-41 409.5,-41 409.5,-47 403.5,-53 397.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"355.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"355.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"355.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M364.603,-88.9485C363.37,-80.6238 362.041,-71.6509 360.789,-63.2027\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.241,-62.6158 359.313,-53.2367 357.316,-63.6417 364.241,-62.6158\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.890196\" stroke=\"black\" d=\"M541,-53C541,-53 440,-53 440,-53 434,-53 428,-47 428,-41 428,-41 428,-12 428,-12 428,-6 434,-0 440,-0 440,-0 541,-0 541,-0 547,-0 553,-6 553,-12 553,-12 553,-41 553,-41 553,-47 547,-53 541,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"490.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\r\n",
       "<text text-anchor=\"middle\" x=\"490.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"490.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M411.82,-88.9485C424.002,-79.4346 437.268,-69.074 449.376,-59.6175\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"451.819,-62.1504 457.546,-53.2367 447.511,-56.6335 451.819,-62.1504\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M586.5,-149.5C586.5,-149.5 502.5,-149.5 502.5,-149.5 496.5,-149.5 490.5,-143.5 490.5,-137.5 490.5,-137.5 490.5,-108.5 490.5,-108.5 490.5,-102.5 496.5,-96.5 502.5,-96.5 502.5,-96.5 586.5,-96.5 586.5,-96.5 592.5,-96.5 598.5,-102.5 598.5,-108.5 598.5,-108.5 598.5,-137.5 598.5,-137.5 598.5,-143.5 592.5,-149.5 586.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"544.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"544.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"544.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M552.604,-192.884C551.349,-182.216 549.953,-170.352 548.679,-159.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"552.147,-159.042 547.502,-149.52 545.195,-159.86 552.147,-159.042\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.976471\" stroke=\"black\" d=\"M778,-157C778,-157 629,-157 629,-157 623,-157 617,-151 617,-145 617,-145 617,-101 617,-101 617,-95 623,-89 629,-89 629,-89 778,-89 778,-89 784,-89 790,-95 790,-101 790,-101 790,-145 790,-145 790,-151 784,-157 778,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"703.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst concavity &lt;= 0.191</text>\r\n",
       "<text text-anchor=\"middle\" x=\"703.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 137</text>\r\n",
       "<text text-anchor=\"middle\" x=\"703.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [134, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"703.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M604.227,-192.884C618.032,-183.304 633.227,-172.761 647.489,-162.864\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"649.541,-165.701 655.761,-157.125 645.55,-159.95 649.541,-165.701\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.333333\" stroke=\"black\" d=\"M706.5,-53C706.5,-53 622.5,-53 622.5,-53 616.5,-53 610.5,-47 610.5,-41 610.5,-41 610.5,-12 610.5,-12 610.5,-6 616.5,-0 622.5,-0 622.5,-0 706.5,-0 706.5,-0 712.5,-0 718.5,-6 718.5,-12 718.5,-12 718.5,-41 718.5,-41 718.5,-47 712.5,-53 706.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"664.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"664.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"664.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M689.86,-88.9485C686.349,-80.4408 682.558,-71.2562 679.005,-62.6464\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"682.172,-61.1452 675.121,-53.2367 675.701,-63.8157 682.172,-61.1452\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M850,-53C850,-53 749,-53 749,-53 743,-53 737,-47 737,-41 737,-41 737,-12 737,-12 737,-6 743,-0 749,-0 749,-0 850,-0 850,-0 856,-0 862,-6 862,-12 862,-12 862,-41 862,-41 862,-47 856,-53 850,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"799.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 132</text>\r\n",
       "<text text-anchor=\"middle\" x=\"799.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [132, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"799.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>10&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737.076,-88.9485C746.462,-79.709 756.66,-69.671 766.039,-60.4381\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"768.684,-62.7462 773.355,-53.2367 763.773,-57.7576 768.684,-62.7462\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x227394ac470>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "# Create image of tree with graphviz\n",
    "dot_data = export_graphviz(tree, out_file=None, class_names=[\"malignant\", \"benign\"],feature_names=cancer.feature_names, impurity=False, filled=True, rounded=True)\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "pydot_graph.set_size('\"10,10!\"')\n",
    "\n",
    "gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
    "gvz_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Ensembles`  are  methods  that  combine  multiple  machine  learning  models  to  create more  powerful  models.\n",
    "\n",
    "There are two ensemble models that can be used with decision trees, `Random Forests` and `Gradient boosted regression trees`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests is essentially a collection of decision trees, where each tree is slightly different from the others.\n",
    "\n",
    "The idea of Random Forests is that if we build many trees, all of which work well and overfit in different ways, we can reduce the amount of overfitting by averaging their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a random forest with `100 estimators` (the number of trees in the forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the random forest gives us a great accuracy of 97,2%. This is better than most linear models and single decision trees.\n",
    "\n",
    "Let's see if we can do better by applying some `pre-pruning`(spesifying a max tree depth) and adjusting the `max_features` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.986\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 7, max_features= 30, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the accuracy has improved to 98,6%.\n",
    "\n",
    "You can, like most sklearn, use `Grid Search` to find the optimal parameters for a given model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosted regression tree is another ensemble method that combines multiple decision trees to create a more powerful model. It can be used both for regression and classification.\n",
    "\n",
    "In contrast to the random forest  approach, gradient boosting works by  building trees in a serial manner, where each tree tries to correct the mistakes of the previous one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the training accuracy is 100%, this is probably because it has overfitted.\n",
    "\n",
    "Gradient boosted regression trees can have great accuracy, but it is generally more sensitive to parameter settings than random forests.\n",
    "\n",
    "Let's use `GridSearchCV` to improve our parameters. Grid search is used to search multiple combinations of parameters on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 294 candidates, totalling 2940 fits\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2940 out of 2940 | elapsed:  3.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"max_depth\":[1,3,5],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[100]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=10, verbose= 1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.15, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100, 'subsample': 0.618}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excersise\n",
    "\n",
    "1. Split data\n",
    "\n",
    "2. Classify with Decision Tree\n",
    "\n",
    "3. Classify with a Random Forest\n",
    "\n",
    "4. Classify with a Gradient Boosted Regression Tree\n",
    "\n",
    "5. What is the best accuracy you achieved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.load_iris()\n",
    "\n",
    "# Split data\n",
    "\n",
    "# Classify with decision tree\n",
    "\n",
    "# Classify with a Random Forest\n",
    "\n",
    "# Classify with a Gradient Boosted Regression Tree\n",
    "\n",
    "# What is the best accuracy you achieved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Deep learning\" is all the rage in machine learning at the moment, and there is a plethora of different types of neural networks.\n",
    "\n",
    "Here we will look at the simplest type of neural network, the `multilayer perceptron` or `feed-forward neural network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"252pt\" height=\"261pt\"\r\n",
       " viewBox=\"0.00 0.00 252.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-257 248,-257 248,4 -4,4\"/>\r\n",
       "<g id=\"clust1\" class=\"cluster\"><title>cluster_0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"white\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">inputs</text>\r\n",
       "</g>\r\n",
       "<g id=\"clust3\" class=\"cluster\"><title>cluster_2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"white\" points=\"184,-89 184,-164 237,-164 237,-89 184,-89\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-148.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output</text>\r\n",
       "</g>\r\n",
       "<g id=\"clust2\" class=\"cluster\"><title>cluster_1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"white\" points=\"80,-35 80,-218 164,-218 164,-35 80,-35\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-202.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hidden layer</text>\r\n",
       "</g>\r\n",
       "<!-- x[0] -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>x[0]</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x[0]</text>\r\n",
       "</g>\r\n",
       "<!-- h0 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>h0</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"122\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-57.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h[0]</text>\r\n",
       "</g>\r\n",
       "<!-- x[0]&#45;&gt;h0 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>x[0]&#45;&gt;h0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.5321,-181.037C59.3841,-157.723 88.1768,-112.525 105.882,-84.7317\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.004,-86.3447 111.425,-76.0302 103.1,-82.5838 109.004,-86.3447\"/>\r\n",
       "</g>\r\n",
       "<!-- h1 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>h1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"122\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-165.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h[1]</text>\r\n",
       "</g>\r\n",
       "<!-- x[0]&#45;&gt;h1 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>x[0]&#45;&gt;h1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.5817,-190.794C63.836,-186.947 80.7639,-181.632 94.8355,-177.214\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.9768,-180.525 104.469,-174.19 93.88,-173.846 95.9768,-180.525\"/>\r\n",
       "</g>\r\n",
       "<!-- h2 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>h2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"122\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-111.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h[2]</text>\r\n",
       "</g>\r\n",
       "<!-- x[0]&#45;&gt;h2 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>x[0]&#45;&gt;h2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6896,-184.048C61.6628,-170.887 84.3244,-149.543 100.757,-134.066\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.379,-136.405 108.258,-127.001 98.5791,-131.309 103.379,-136.405\"/>\r\n",
       "</g>\r\n",
       "<!-- x[1] -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>x[1]</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x[1]</text>\r\n",
       "</g>\r\n",
       "<!-- x[1]&#45;&gt;h0 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>x[1]&#45;&gt;h0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6896,-130.048C61.6628,-116.887 84.3244,-95.5433 100.757,-80.066\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.379,-82.405 108.258,-73.0009 98.5791,-77.3093 103.379,-82.405\"/>\r\n",
       "</g>\r\n",
       "<!-- x[1]&#45;&gt;h1 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>x[1]&#45;&gt;h1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.5817,-147.206C63.836,-151.053 80.7639,-156.368 94.8355,-160.786\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.88,-164.154 104.469,-163.81 95.9768,-157.475 93.88,-164.154\"/>\r\n",
       "</g>\r\n",
       "<!-- x[1]&#45;&gt;h2 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>x[1]&#45;&gt;h2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.5817,-136.794C63.836,-132.947 80.7639,-127.632 94.8355,-123.214\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.9768,-126.525 104.469,-120.19 93.88,-119.846 95.9768,-126.525\"/>\r\n",
       "</g>\r\n",
       "<!-- x[2] -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>x[2]</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x[2]</text>\r\n",
       "</g>\r\n",
       "<!-- x[2]&#45;&gt;h0 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>x[2]&#45;&gt;h0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.5817,-82.7941C63.836,-78.9468 80.7639,-73.6323 94.8355,-69.2144\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.9768,-72.5246 104.469,-66.1899 93.88,-65.846 95.9768,-72.5246\"/>\r\n",
       "</g>\r\n",
       "<!-- x[2]&#45;&gt;h1 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>x[2]&#45;&gt;h1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6896,-99.9518C61.6628,-113.113 84.3244,-134.457 100.757,-149.934\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.5791,-152.691 108.258,-156.999 103.379,-147.595 98.5791,-152.691\"/>\r\n",
       "</g>\r\n",
       "<!-- x[2]&#45;&gt;h2 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>x[2]&#45;&gt;h2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.5817,-93.2059C63.836,-97.0532 80.7639,-102.368 94.8355,-106.786\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.88,-110.154 104.469,-109.81 95.9768,-103.475 93.88,-110.154\"/>\r\n",
       "</g>\r\n",
       "<!-- x[3] -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>x[3]</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x[3]</text>\r\n",
       "</g>\r\n",
       "<!-- x[3]&#45;&gt;h0 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>x[3]&#45;&gt;h0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.5817,-39.2059C63.836,-43.0532 80.7639,-48.3677 94.8355,-52.7856\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.88,-56.154 104.469,-55.8101 95.9768,-49.4754 93.88,-56.154\"/>\r\n",
       "</g>\r\n",
       "<!-- x[3]&#45;&gt;h1 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>x[3]&#45;&gt;h1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.5321,-48.9632C59.3841,-72.2774 88.1768,-117.475 105.882,-145.268\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.1,-147.416 111.425,-153.97 109.004,-143.655 103.1,-147.416\"/>\r\n",
       "</g>\r\n",
       "<!-- x[3]&#45;&gt;h2 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>x[3]&#45;&gt;h2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6896,-45.9518C61.6628,-59.1126 84.3244,-80.4567 100.757,-95.934\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.5791,-98.6907 108.258,-102.999 103.379,-93.595 98.5791,-98.6907\"/>\r\n",
       "</g>\r\n",
       "<!-- y -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>y</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"210\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-111.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">y</text>\r\n",
       "</g>\r\n",
       "<!-- h0&#45;&gt;y -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>h0&#45;&gt;y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137.589,-70.1604C150.685,-78.3836 170.145,-90.6029 185.445,-100.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.01,-103.441 194.34,-105.795 187.732,-97.5129 184.01,-103.441\"/>\r\n",
       "</g>\r\n",
       "<!-- h1&#45;&gt;y -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>h1&#45;&gt;y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137.589,-159.84C150.685,-151.616 170.145,-139.397 185.445,-129.79\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.732,-132.487 194.34,-124.205 184.01,-126.559 187.732,-132.487\"/>\r\n",
       "</g>\r\n",
       "<!-- h2&#45;&gt;y -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>h2&#45;&gt;y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.403,-115C152.254,-115 168.183,-115 181.708,-115\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.916,-118.5 191.916,-115 181.916,-111.5 181.916,-118.5\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2273a92f208>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_single_hidden_layer_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the prediction by a linear regressor is given as:\n",
    "\n",
    "`ŷ = w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b`\n",
    "\n",
    "ŷ  is  a  weighted  sum  of  the  input  features  x[0]  to  x[p],  weighted  by the learned coefficients w[0] to w[p].\n",
    "\n",
    "A neural network trains by changing its weights a little bit (depending on the learning rate) for each data point in the training data using `Gradient Descent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/1600/0*QwE8M4MupSdqA3M4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the learning rate decides how much the weights should be adjusted for each iteration. \n",
    "\n",
    "- If the learning rate is too large, the model will not improve or even get worse for each iteration.\n",
    "\n",
    "- If the learning rate is too small however, the model will take forever to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example with the breast cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.91\n",
      "Accuracy on test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of 88% is good but not great. This may be because the neural network expects its inputs to be `normalzed`. The imput numbers should ideally have a mean of 0, and a variance of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.993\n",
      "Accuracy on test set: 0.972\n"
     ]
    }
   ],
   "source": [
    "# compute the mean value per feature on the training set\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# compute the standard deviation of each feature on the training set\n",
    "std_on_train = X_train.std(axis=0)\n",
    "# subtract the mean, and scale by inverse standard deviation\n",
    "# afterward, mean=0 and std=1\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "# use THE SAME transformation (using training mean and std) on the test set\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    "\n",
    "mlp = MLPClassifier(random_state=0, max_iter=1000)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the accuracy is much better with `normalized` input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add 3 hidden layers with sizes [256, 256, 100] and see if the network improves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.965\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=0, max_iter=10000, hidden_layer_sizes=[100, 100], learning_rate='adaptive')\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural nework uses an activation function on the inputs of each node before feeding a value to the next node.\n",
    "\n",
    "The `MLPClassifier`can use a variety of activation functions:<br> `identity`, `logistic`, `tanh` and `relu` with `relu` as default\n",
    "\n",
    "Let's see how our classifier performs with a logistic activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.984\n",
      "Accuracy on test set: 0.951\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=0, activation='logistic', max_iter=10000, hidden_layer_sizes=[256, 256, 100])\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to give you a peek into the world of deep learning, here is a cheat sheet:\n",
    "\n",
    "![image](https://cdn-images-1.medium.com/max/1500/1*gccuMDV8fXjcvz1RSk4kgQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  3., 13., ..., 12.,  9.,  1.],\n",
       "       [ 0.,  0.,  1., ..., 13.,  1.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  9.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., ..., 11.,  0.,  0.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray()\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=False, sharey=False)\n",
    "ax1.matshow(digits.images[0])\n",
    "ax2.matshow(digits.images[2])\n",
    "ax3.matshow(digits.images[3])\n",
    "ax4.matshow(digits.images[4])\n",
    "plt.show() \n",
    "\n",
    "# Create MLP classifier\n",
    "\n",
    "# classify digits\n",
    "\n",
    "print(X_train.max())\n",
    "# Try with a larger dataset\n",
    "\n",
    "# Plot ad hoc mnist instances\n",
    "#!pip install keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.984\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  1  actual label:  8\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  5  actual label:  9\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  9  actual label:  5\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  1  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  8  actual label:  1\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  2  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  1  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  8  actual label:  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  0  actual label:  0\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  0  actual label:  0\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  4  actual label:  4\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  9  actual label:  9\n",
      "predictions:  8  actual label:  8\n",
      "predictions:  3  actual label:  3\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  6  actual label:  6\n",
      "predictions:  2  actual label:  2\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  7  actual label:  7\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  5  actual label:  5\n",
      "predictions:  1  actual label:  1\n",
      "predictions:  9  actual label:  9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mlp = MLPClassifier(random_state=0, activation='relu',hidden_layer_sizes=[256, 256], max_iter=100000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, y_test)))\n",
    "\n",
    "predictions = mlp.predict(X_test);\n",
    "for i in range(len(predictions)):\n",
    "    print('prediction: ' , predictions[i], \" actual label: \", y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.984\n",
      "[[ 0.         -0.33833791  1.20529484 ...  1.06879069  3.49353218\n",
      "   4.38404091]\n",
      " [ 0.          0.7264779   2.03990846 ... -0.97014862 -0.49971129\n",
      "  -0.18751172]\n",
      " [ 0.          1.79129371  1.62260165 ...  1.57852552  3.49353218\n",
      "   1.52682052]\n",
      " ...\n",
      " [ 0.         -0.33833791  1.20529484 ...  0.04932104 -0.49971129\n",
      "  -0.18751172]\n",
      " [ 0.         -0.33833791 -0.04662559 ...  0.04932104 -0.49971129\n",
      "  -0.18751172]\n",
      " [ 0.          1.79129371  1.83125505 ... -0.12059057 -0.49971129\n",
      "  -0.18751172]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#print(X_train_scaled)\n",
    "\n",
    "mlp = MLPClassifier(random_state=5, activation='relu',hidden_layer_sizes=[256, 256], max_iter=100000)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Reckognition with the MNSIT data set\n",
    "\n",
    "## Excersise\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html \n",
    "\n",
    "or\n",
    "\n",
    "The mnist digit dataset contains 60 000 images of handwritten digits.\n",
    "The images have a resolution of 28x28 and a grayscale value of 0-255 for each pixel.\n",
    "\n",
    "Use the sklean MLPClassifier to create a neural network and classify the images.\n",
    "\n",
    "Files can also be downloaded here: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.datasets import mnist\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data from (60000, 28, 28) to (60000, 784)\n",
    "#X_train = X_train.reshape((len(X_train), -1))\n",
    "#X_test = X_test.reshape((len(X_test), -1))\n",
    "\n",
    "# Rescale the data, it is 0-255 and you want it closer to 0-1.\n",
    "\n",
    "# Create MLPClassifier.\n",
    "\n",
    "# Fit data to classifier.\n",
    "\n",
    "# Test accuracy of classifier on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray()\n",
    "plt.matshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsors\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.996\n",
      "Accuracy on test set: 0.974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data from (60000, 28, 28) to (60000, 784)\n",
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "X_test = X_test.reshape((len(X_test), -1))\n",
    "\n",
    "# Rescale the data, it is 0-255 and you want it closer to 0-1.\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Create MLPClassifier.\n",
    "mlp = MLPClassifier(random_state=5, activation='relu',hidden_layer_sizes=[256, 256], max_iter=100000)\n",
    "# Fit data to classifier.\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test accuracy of classifier on test data.\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not part of curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple neural network with one hidden (Dense) layer of size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create neural network model\n",
    "def simple_nn(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/15\n",
      " - 3s - loss: 0.4781 - acc: 0.8695 - val_loss: 0.2623 - val_acc: 0.9250\n",
      "Epoch 2/15\n",
      " - 2s - loss: 0.2224 - acc: 0.9361 - val_loss: 0.1974 - val_acc: 0.9441\n",
      "Epoch 3/15\n",
      " - 2s - loss: 0.1659 - acc: 0.9520 - val_loss: 0.1637 - val_acc: 0.9536\n",
      "Epoch 4/15\n",
      " - 1s - loss: 0.1333 - acc: 0.9615 - val_loss: 0.1426 - val_acc: 0.9596\n",
      "Epoch 5/15\n",
      " - 2s - loss: 0.1105 - acc: 0.9690 - val_loss: 0.1370 - val_acc: 0.9603\n",
      "Epoch 6/15\n",
      " - 1s - loss: 0.0947 - acc: 0.9731 - val_loss: 0.1226 - val_acc: 0.9641\n",
      "Epoch 7/15\n",
      " - 2s - loss: 0.0814 - acc: 0.9771 - val_loss: 0.1144 - val_acc: 0.9672\n",
      "Epoch 8/15\n",
      " - 2s - loss: 0.0692 - acc: 0.9809 - val_loss: 0.1119 - val_acc: 0.9674\n",
      "Epoch 9/15\n",
      " - 2s - loss: 0.0600 - acc: 0.9830 - val_loss: 0.1056 - val_acc: 0.9681\n",
      "Epoch 10/15\n",
      " - 2s - loss: 0.0527 - acc: 0.9854 - val_loss: 0.1030 - val_acc: 0.9686\n",
      "Epoch 11/15\n",
      " - 2s - loss: 0.0460 - acc: 0.9884 - val_loss: 0.1003 - val_acc: 0.9707\n",
      "Epoch 12/15\n",
      " - 2s - loss: 0.0411 - acc: 0.9894 - val_loss: 0.0982 - val_acc: 0.9704\n",
      "Epoch 13/15\n",
      " - 2s - loss: 0.0362 - acc: 0.9909 - val_loss: 0.0983 - val_acc: 0.9708\n",
      "Epoch 14/15\n",
      " - 2s - loss: 0.0320 - acc: 0.9924 - val_loss: 0.0973 - val_acc: 0.9713\n",
      "Epoch 15/15\n",
      " - 2s - loss: 0.0277 - acc: 0.9936 - val_loss: 0.0949 - val_acc: 0.9724\n",
      "[0.0794167518065311, 0.9764]\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data from (60000, 28, 28) to (60000, 784)\n",
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "X_test = X_test.reshape((len(X_test), -1))\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Make labels categorical\n",
    "y_train_categorical = np_utils.to_categorical(y_train)\n",
    "y_test_categorical = np_utils.to_categorical(y_test)\n",
    "print(X_train.shape)\n",
    "\n",
    "nn = simple_nn(10)\n",
    "\n",
    "# Fit data\n",
    "nn.fit(X_train, y_train_categorical, validation_split=0.3, epochs=15, batch_size=200, verbose=2)\n",
    "\n",
    "score = nn.evaluate(X_test, y_test_categorical, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network with 2 convolutional layers, 1 pooling layer and 1 dense layer.\n",
    "\n",
    "CNN explained: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "\n",
    "This implementation is probably gonna be a bit slow if you're not using tensorflow-gpu, you can remove the second convolutional layer to improve training speed without a large drop in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "def convolutional_neural_network_model(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/15\n",
      " - 21s - loss: 0.4158 - acc: 0.8710 - val_loss: 0.1242 - val_acc: 0.9634\n",
      "Epoch 2/15\n",
      " - 21s - loss: 0.1335 - acc: 0.9625 - val_loss: 0.0763 - val_acc: 0.9767\n",
      "Epoch 3/15\n",
      " - 21s - loss: 0.0912 - acc: 0.9726 - val_loss: 0.0603 - val_acc: 0.9813\n",
      "Epoch 4/15\n",
      " - 21s - loss: 0.0698 - acc: 0.9789 - val_loss: 0.0527 - val_acc: 0.9837\n",
      "Epoch 5/15\n",
      " - 21s - loss: 0.0588 - acc: 0.9824 - val_loss: 0.0485 - val_acc: 0.9856\n",
      "Epoch 6/15\n",
      " - 23s - loss: 0.0490 - acc: 0.9852 - val_loss: 0.0463 - val_acc: 0.9860\n",
      "Epoch 7/15\n",
      " - 23s - loss: 0.0415 - acc: 0.9867 - val_loss: 0.0464 - val_acc: 0.9873\n",
      "Epoch 8/15\n",
      " - 28s - loss: 0.0353 - acc: 0.9888 - val_loss: 0.0438 - val_acc: 0.9873\n",
      "Epoch 9/15\n",
      " - 31s - loss: 0.0343 - acc: 0.9891 - val_loss: 0.0422 - val_acc: 0.9890\n",
      "Epoch 10/15\n",
      " - 31s - loss: 0.0305 - acc: 0.9903 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "Epoch 11/15\n",
      " - 31s - loss: 0.0278 - acc: 0.9907 - val_loss: 0.0420 - val_acc: 0.9889\n",
      "Epoch 12/15\n",
      " - 31s - loss: 0.0239 - acc: 0.9921 - val_loss: 0.0459 - val_acc: 0.9885\n",
      "Epoch 13/15\n",
      " - 27s - loss: 0.0224 - acc: 0.9923 - val_loss: 0.0442 - val_acc: 0.9893\n",
      "Epoch 14/15\n",
      " - 24s - loss: 0.0214 - acc: 0.9926 - val_loss: 0.0458 - val_acc: 0.9886\n",
      "Epoch 15/15\n",
      " - 24s - loss: 0.0214 - acc: 0.9926 - val_loss: 0.0438 - val_acc: 0.9892\n",
      "[0.02968060653191219, 0.9912]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Make labels categorical\n",
    "y_train_categorical = np_utils.to_categorical(y_train)\n",
    "y_test_categorical = np_utils.to_categorical(y_test)\n",
    "num_classes = y_train_categorical.shape[1]\n",
    "# Reshape data for cnn\n",
    "x_train_c = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "x_test_c = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# Create cnn model\n",
    "cnn = convolutional_neural_network_model(num_classes)\n",
    "\n",
    "# Fit data\n",
    "cnn.fit(x_train_c, y_train_categorical, validation_split=0.3, epochs=15, batch_size=200, verbose=2)\n",
    "\n",
    "# Check accuracy\n",
    "score = cnn.evaluate(x_test_c, y_test_categorical, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
